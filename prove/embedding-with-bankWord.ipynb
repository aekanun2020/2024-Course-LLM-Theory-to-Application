{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ebb678-d83a-498f-ad7f-9c79aea027f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I need to go to the bank to deposit some money.\n",
      "Tokens: ['i', 'need', 'to', 'go', 'to', 'the', 'bank', 'to', 'deposit', 'some', 'money', '.']\n",
      "Token IDs: [1045, 2342, 2000, 2175, 2000, 1996, 2924, 2000, 12816, 2070, 2769, 1012]\n",
      "Decoded: i need to go to the bank to deposit some money.\n",
      "\n",
      "Text: The river bank was overgrown with wildflowers.\n",
      "Tokens: ['the', 'river', 'bank', 'was', 'overgrown', 'with', 'wild', '##flower', '##s', '.']\n",
      "Token IDs: [1996, 2314, 2924, 2001, 26433, 2007, 3748, 14156, 2015, 1012]\n",
      "Decoded: the river bank was overgrown with wildflowers.\n",
      "\n",
      "Text: The pilot had to bank the airplane to avoid turbulence.\n",
      "Tokens: ['the', 'pilot', 'had', 'to', 'bank', 'the', 'airplane', 'to', 'avoid', 'turbulence', '.']\n",
      "Token IDs: [1996, 4405, 2018, 2000, 2924, 1996, 13297, 2000, 4468, 29083, 1012]\n",
      "Decoded: the pilot had to bank the airplane to avoid turbulence.\n",
      "\n",
      "Text: You can bank on me to finish the project on time.\n",
      "Tokens: ['you', 'can', 'bank', 'on', 'me', 'to', 'finish', 'the', 'project', 'on', 'time', '.']\n",
      "Token IDs: [2017, 2064, 2924, 2006, 2033, 2000, 3926, 1996, 2622, 2006, 2051, 1012]\n",
      "Decoded: you can bank on me to finish the project on time.\n",
      "\n",
      "Text: The food bank is collecting donations for the homeless.\n",
      "Tokens: ['the', 'food', 'bank', 'is', 'collecting', 'donations', 'for', 'the', 'homeless', '.']\n",
      "Token IDs: [1996, 2833, 2924, 2003, 9334, 11440, 2005, 1996, 11573, 1012]\n",
      "Decoded: the food bank is collecting donations for the homeless.\n",
      "\n",
      "Text: They're going to bank the fires for the night.\n",
      "Tokens: ['they', \"'\", 're', 'going', 'to', 'bank', 'the', 'fires', 'for', 'the', 'night', '.']\n",
      "Token IDs: [2027, 1005, 2128, 2183, 2000, 2924, 1996, 8769, 2005, 1996, 2305, 1012]\n",
      "Decoded: they're going to bank the fires for the night.\n",
      "\n",
      "Text: The pool player tried to bank the shot off the cushion.\n",
      "Tokens: ['the', 'pool', 'player', 'tried', 'to', 'bank', 'the', 'shot', 'off', 'the', 'cushion', '.']\n",
      "Token IDs: [1996, 4770, 2447, 2699, 2000, 2924, 1996, 2915, 2125, 1996, 22936, 1012]\n",
      "Decoded: the pool player tried to bank the shot off the cushion.\n",
      "\n",
      "Text: The company has a large piggy bank of cash reserves.\n",
      "Tokens: ['the', 'company', 'has', 'a', 'large', 'pig', '##gy', 'bank', 'of', 'cash', 'reserves', '.']\n",
      "Token IDs: [1996, 2194, 2038, 1037, 2312, 10369, 6292, 2924, 1997, 5356, 8269, 1012]\n",
      "Decoded: the company has a large piggy bank of cash reserves.\n",
      "\n",
      "Text: Banksy is a famous street artist.\n",
      "Tokens: ['banks', '##y', 'is', 'a', 'famous', 'street', 'artist', '.']\n",
      "Token IDs: [5085, 2100, 2003, 1037, 3297, 2395, 3063, 1012]\n",
      "Decoded: banksy is a famous street artist.\n",
      "\n",
      "Text: The bank holiday means all offices will be closed on Monday.\n",
      "Tokens: ['the', 'bank', 'holiday', 'means', 'all', 'offices', 'will', 'be', 'closed', 'on', 'monday', '.']\n",
      "Token IDs: [1996, 2924, 6209, 2965, 2035, 4822, 2097, 2022, 2701, 2006, 6928, 1012]\n",
      "Decoded: the bank holiday means all offices will be closed on monday.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to tokenize and print results\n",
    "def tokenize_and_print(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print(\"Token IDs:\", token_ids)\n",
    "    print(\"Decoded:\", tokenizer.decode(token_ids))\n",
    "    print()\n",
    "\n",
    "# Examples of \"bank\" in different contexts\n",
    "examples = [\n",
    "    \"I need to go to the bank to deposit some money.\",\n",
    "    \"The river bank was overgrown with wildflowers.\",\n",
    "    \"The pilot had to bank the airplane to avoid turbulence.\",\n",
    "    \"You can bank on me to finish the project on time.\",\n",
    "    \"The food bank is collecting donations for the homeless.\",\n",
    "    \"They're going to bank the fires for the night.\",\n",
    "    \"The pool player tried to bank the shot off the cushion.\",\n",
    "    \"The company has a large piggy bank of cash reserves.\",\n",
    "    \"Banksy is a famous street artist.\",\n",
    "    \"The bank holiday means all offices will be closed on Monday.\"\n",
    "]\n",
    "\n",
    "# Tokenize and print each example\n",
    "for example in examples:\n",
    "    tokenize_and_print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9c478a-2f51-4ae7-89cf-e973aa71a2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc79bee6660b4e4abb439b77378b60f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I need to go to the bank to deposit some money.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.64034605 -0.18108568  0.11862013 -0.2020568   1.3855611 ]\n",
      "\n",
      "Sentence 2: The river bank was overgrown with wildflowers.\n",
      "Embedding for 'bank' (first 5 dimensions): [-0.17355233 -0.5053988  -0.19030745 -0.51391476 -0.2884438 ]\n",
      "\n",
      "Sentence 3: The pilot had to bank the airplane to avoid turbulence.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.23946215 -0.21487379 -0.16276157  0.3818572   0.22607988]\n",
      "\n",
      "Sentence 4: You can bank on me to finish the project on time.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 1.0760132  -0.6041027   0.3984626  -0.35869265  1.0072378 ]\n",
      "\n",
      "Sentence 5: The food bank is collecting donations for the homeless.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.21331732 -0.6920833  -0.1706988   0.0951876   1.011391  ]\n",
      "\n",
      "Cosine Similarities:\n",
      "1.0000\t0.4407\t0.3670\t0.5065\t0.5533\t\n",
      "0.4407\t1.0000\t0.3886\t0.4106\t0.4724\t\n",
      "0.3670\t0.3886\t1.0000\t0.4654\t0.3232\t\n",
      "0.5065\t0.4106\t0.4654\t1.0000\t0.4035\t\n",
      "0.5533\t0.4724\t0.3232\t0.4035\t1.0000\t\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get contextual embedding for a specific word\n",
    "def get_word_embedding(sentence, word):\n",
    "    # Tokenize the sentence\n",
    "    inputs = tokenizer(sentence, return_tensors='pt')\n",
    "    \n",
    "    # Get model output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the last hidden state\n",
    "    last_hidden_state = outputs.last_hidden_state[0]\n",
    "    \n",
    "    # Find the position of the word\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    input_tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    word_position = input_tokens.index(word_tokens[0])\n",
    "    \n",
    "    # Get the embedding for the word\n",
    "    word_embedding = last_hidden_state[word_position].numpy()\n",
    "    \n",
    "    return word_embedding\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"I need to go to the bank to deposit some money.\",\n",
    "    \"The river bank was overgrown with wildflowers.\",\n",
    "    \"The pilot had to bank the airplane to avoid turbulence.\",\n",
    "    \"You can bank on me to finish the project on time.\",\n",
    "    \"The food bank is collecting donations for the homeless.\"\n",
    "]\n",
    "\n",
    "# Get embeddings for 'bank' in each context\n",
    "embeddings = [get_word_embedding(sentence, 'bank') for sentence in sentences]\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# Compute pairwise similarities\n",
    "similarities = np.zeros((len(embeddings), len(embeddings)))\n",
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        similarities[i][j] = cosine_similarity(embeddings[i], embeddings[j])\n",
    "\n",
    "# Print results\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Sentence {i+1}: {sentence}\")\n",
    "    print(f\"Embedding for 'bank' (first 5 dimensions): {embeddings[i][:5]}\")\n",
    "    print()\n",
    "\n",
    "print(\"Cosine Similarities:\")\n",
    "for i in range(len(similarities)):\n",
    "    for j in range(len(similarities)):\n",
    "        print(f\"{similarities[i][j]:.4f}\", end=\"\\t\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bdbab3-d2a4-4e15-bff3-60634d2bd97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
