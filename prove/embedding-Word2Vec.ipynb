{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef23cfa8-7b2e-41ec-ad8c-b5345bebb722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   135  100   135    0     0    365      0 --:--:-- --:--:-- --:--:--   365\n"
     ]
    }
   ],
   "source": [
    "! curl -LO https://raw.githubusercontent.com/mmihaltz/word2vec-GoogleNews-vectors/master/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40f1122-7336-4bba-9302-030261995ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/grizzlystudio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I need to go to the bank to deposit some money.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.02197266  0.13476562 -0.05786133  0.05566406  0.09912109]\n",
      "\n",
      "Sentence 2: The river bank was overgrown with wildflowers.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.02197266  0.13476562 -0.05786133  0.05566406  0.09912109]\n",
      "\n",
      "Sentence 3: The pilot had to bank the airplane to avoid turbulence.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.02197266  0.13476562 -0.05786133  0.05566406  0.09912109]\n",
      "\n",
      "Sentence 4: You can bank on me to finish the project on time.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.02197266  0.13476562 -0.05786133  0.05566406  0.09912109]\n",
      "\n",
      "Sentence 5: The food bank is collecting donations for the homeless.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.02197266  0.13476562 -0.05786133  0.05566406  0.09912109]\n",
      "\n",
      "Sentence 6: The central bank announced new interest rates to stabilize the economy.\n",
      "Embedding for 'bank' (first 5 dimensions): [ 0.02197266  0.13476562 -0.05786133  0.05566406  0.09912109]\n",
      "\n",
      "Cosine Similarities:\n",
      "1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t\n",
      "1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t\n",
      "1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t\n",
      "1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t\n",
      "1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t\n",
      "1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t1.0000\t\n",
      "\n",
      "Most similar pair of sentences for 'bank':\n",
      "Sentence 1 and Sentence 2\n",
      "Similarity: 1.0000\n",
      "\n",
      "Sentence 1: I need to go to the bank to deposit some money.\n",
      "\n",
      "Sentence 2: The river bank was overgrown with wildflowers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "# Note: You need to download the model file first\n",
    "# You can use: !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "# Function to get word embedding\n",
    "def get_word_embedding(sentence, target_word):\n",
    "    # Tokenize the sentence\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    \n",
    "    # Find the position of the target word\n",
    "    try:\n",
    "        word_position = tokens.index(target_word.lower())\n",
    "    except ValueError:\n",
    "        print(f\"'{target_word}' not found in the sentence.\")\n",
    "        return None\n",
    "    \n",
    "    # Get the embedding for the word\n",
    "    try:\n",
    "        word_embedding = model[tokens[word_position]]\n",
    "    except KeyError:\n",
    "        print(f\"'{tokens[word_position]}' not in vocabulary.\")\n",
    "        return None\n",
    "    \n",
    "    return word_embedding\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    \"I need to go to the bank to deposit some money.\",\n",
    "    \"The river bank was overgrown with wildflowers.\",\n",
    "    \"The pilot had to bank the airplane to avoid turbulence.\",\n",
    "    \"You can bank on me to finish the project on time.\",\n",
    "    \"The food bank is collecting donations for the homeless.\",\n",
    "    \"The central bank announced new interest rates to stabilize the economy.\"\n",
    "]\n",
    "\n",
    "# Get embeddings for 'bank' in each context\n",
    "embeddings = [get_word_embedding(sentence, 'bank') for sentence in sentences]\n",
    "\n",
    "# Remove None values if any\n",
    "embeddings = [e for e in embeddings if e is not None]\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "# Compute pairwise similarities\n",
    "similarities = np.zeros((len(embeddings), len(embeddings)))\n",
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        similarities[i][j] = cosine_similarity(embeddings[i], embeddings[j])\n",
    "\n",
    "# Print results\n",
    "for i, sentence in enumerate(sentences):\n",
    "    if i < len(embeddings):\n",
    "        print(f\"Sentence {i+1}: {sentence}\")\n",
    "        print(f\"Embedding for 'bank' (first 5 dimensions): {embeddings[i][:5]}\")\n",
    "        print()\n",
    "\n",
    "print(\"Cosine Similarities:\")\n",
    "for i in range(len(similarities)):\n",
    "    for j in range(len(similarities)):\n",
    "        print(f\"{similarities[i][j]:.4f}\", end=\"\\t\")\n",
    "    print()\n",
    "\n",
    "# Find the most similar pair\n",
    "max_similarity = 0\n",
    "max_pair = (0, 0)\n",
    "for i in range(len(similarities)):\n",
    "    for j in range(i+1, len(similarities)):\n",
    "        if similarities[i][j] > max_similarity:\n",
    "            max_similarity = similarities[i][j]\n",
    "            max_pair = (i, j)\n",
    "\n",
    "print(f\"\\nMost similar pair of sentences for 'bank':\")\n",
    "print(f\"Sentence {max_pair[0]+1} and Sentence {max_pair[1]+1}\")\n",
    "print(f\"Similarity: {max_similarity:.4f}\")\n",
    "print(f\"\\nSentence {max_pair[0]+1}: {sentences[max_pair[0]]}\")\n",
    "print(f\"\\nSentence {max_pair[1]+1}: {sentences[max_pair[1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e6035-f53e-4db1-8bcf-c37d2beaa58c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
