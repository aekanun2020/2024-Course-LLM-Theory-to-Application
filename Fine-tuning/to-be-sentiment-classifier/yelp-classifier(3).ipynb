{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b58ff58-e5ab-436f-821b-2f6154a0d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf fine_tuned_openthaigpt_yelp_lora openthaigpt_yelp_results wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f05288-5a76-4a55-a138-be5f4324da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11079/11079 [00:02<00:00, 4433.64 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2770/2770 [00:00<00:00, 5267.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 11079\n",
      "Number of testing samples: 2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maekanun2020\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/admin/1/wandb/run-20240814_231108-d83957kx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aekanun2020/huggingface/runs/d83957kx' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/aekanun2020/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aekanun2020/huggingface' target=\"_blank\">https://wandb.ai/aekanun2020/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aekanun2020/huggingface/runs/d83957kx' target=\"_blank\">https://wandb.ai/aekanun2020/huggingface/runs/d83957kx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1386' max='1386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1386/1386 10:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.313548</td>\n",
       "      <td>0.880505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.484100</td>\n",
       "      <td>0.280484</td>\n",
       "      <td>0.888087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.318758</td>\n",
       "      <td>0.900361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.318758100271225, 'eval_accuracy': 0.9003610014915466, 'eval_runtime': 18.841, 'eval_samples_per_second': 147.02, 'eval_steps_per_second': 6.157, 'epoch': 3.0}\n",
      "Sentiment: LABEL_0 (Confidence: 1.00)\n",
      "\n",
      "Amenities: The restaurant has parking facilities.\n",
      "Amenities: The restaurant offers Wi-Fi.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, pipeline\n",
    "import random\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_data(file_path, num_samples=100000):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = []\n",
    "        for line in f:\n",
    "            if random.random() < num_samples / 50000000:\n",
    "                item = json.loads(line)\n",
    "                item['sentiment'] = 'positive' if item['stars'] > 3 else 'negative' if item['stars'] < 3 else 'neutral'\n",
    "                data.append(item)\n",
    "            if len(data) >= num_samples:\n",
    "                break\n",
    "    return data\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = load_and_preprocess_data('../yelp_academic_dataset_review.json', num_samples=100000)\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': [item['text'] for item in train_data],\n",
    "    'labels': [{'positive': 0, 'neutral': 1, 'negative': 2}[item['sentiment']] for item in train_data]\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'text': [item['text'] for item in test_data],\n",
    "    'labels': [{'positive': 0, 'neutral': 1, 'negative': 2}[item['sentiment']] for item in test_data]\n",
    "})\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of testing samples: {len(test_dataset)}\")\n",
    "\n",
    "# Load pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Define compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).astype(np.float32).mean().item()}\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# ... (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)\n",
    "\n",
    "# ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à\n",
    "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ tokenizer\n",
    "model_save_path = \"./restaurant_review_model\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ tokenizer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=loaded_model, tokenizer=loaded_tokenizer)\n",
    "\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô analyze_restaurant ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°\n",
    "def analyze_restaurant(review_text):\n",
    "    result = classifier(review_text)[0]\n",
    "    sentiment = result['label']\n",
    "    confidence = result['score']\n",
    "    \n",
    "    analysis = f\"Sentiment: {sentiment} (Confidence: {confidence:.2f})\\n\\n\"\n",
    "    \n",
    "    if \"location\" in review_text.lower():\n",
    "        analysis += \"Location: The review mentions the restaurant's location.\\n\"\n",
    "    \n",
    "    if \"parking\" in review_text.lower():\n",
    "        analysis += \"Amenities: The restaurant has parking facilities.\\n\"\n",
    "    \n",
    "    if \"wifi\" in review_text.lower() or \"wi-fi\" in review_text.lower():\n",
    "        analysis += \"Amenities: The restaurant offers Wi-Fi.\\n\"\n",
    "    \n",
    "    if \"reservation\" in review_text.lower():\n",
    "        analysis += \"Services: The restaurant accepts reservations.\\n\"\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "review = \"The restaurant is located in downtown, with easy parking. The food was amazing and the service was excellent. They also have free Wi-Fi for customers.\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555e2026-13a4-42e4-ac37-7d4bc4025a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0 (Confidence: 0.58)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "review = \"‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏°‡∏≤‡∏Å! ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏™‡∏î‡πÉ‡∏´‡∏°‡πà ‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à ‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏ö‡∏≤‡∏¢‡πÜ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏• ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏≠‡∏µ‡∏Å‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô!\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c143abb5-f640-4074-b380-47fce2d0d265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0 (Confidence: 0.41)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "review = \"‡πÅ‡∏¢‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î! ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏¢‡πà ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏´‡∏¢‡∏≤‡∏ö‡∏Ñ‡∏≤‡∏¢ ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏û‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏™‡∏†‡∏≤‡∏û‡∏£‡πâ‡∏≤‡∏ô‡∏™‡∏Å‡∏õ‡∏£‡∏Å ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏•‡∏¢\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91e7a90d-6f8f-494d-8963-e9a2f5708067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_2 (Confidence: 0.99)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = \"Worst ever! The food tastes terrible, the staff is rude, prices are way too high, and the restaurant is dirty. Absolutely not recommended!\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96108587-9394-4e0a-9baf-ff7bd3b0b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_2 (Confidence: 0.99)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = '''Worst ever! The food tastes terrible, \n",
    "the staff is rude, prices are way too high, and the restaurant is dirty. \n",
    "Absolutely not recommended!'''\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2982f6e9-c73d-4260-91c2-b29dc99ecd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0 (Confidence: 1.00)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = \"Absolutely amazing experience! The food was delicious, service impeccable, and the ambiance perfect for a romantic dinner. Every dish we tried was a masterpiece. Definitely coming back soon!\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95bb10cd-48a2-4a5f-b6ff-6c95bf220598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0 (Confidence: 1.00)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = \"Definitely coming back soon!\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c02954c-e11b-4ba8-9d92-d5a73b94b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0 (Confidence: 1.00)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = \"If you're visiting, don't miss their signature dish - the truffle risotto. It's creamy, aromatic, and absolutely delicious. Make sure to book in advance as it gets pretty busy, especially on weekends.\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10a7bc66-02a6-430f-907d-74fbd37c1ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_1 (Confidence: 0.63)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = \"The food here is excellent, especially the steaks. However, portion sizes are a bit small for the price. The atmosphere is great, but it can get noisy when busy. They could improve by adding more vegetarian options to the menu.\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f61c6cc-a133-4da5-8cef-f72f056995d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0 (Confidence: 0.99)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = \"I've tried most Italian restaurants in town, and this one tops the list. The pasta is homemade and cooked to perfection - way better than the overcooked noodles at that place down the street. Prices are similar to other upscale Italian joints, but the quality here justifies every penny.\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aac71e9f-f811-4a9e-a340-72c89212b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0 (Confidence: 1.00)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = \"I visited this charming little bistro last night and was pleasantly surprised. The decor is rustic yet elegant, creating a cozy atmosphere. We started with the bruschetta, which was fresh and flavorful. For the main course, I had the grilled salmon - perfectly cooked and seasoned. My partner enjoyed the mushroom risotto, rich and creamy. The wine list is impressive, with a good selection of both local and imported wines. Service was attentive without being intrusive. Prices are on the higher side, but justified by the quality. One small issue - the wait time for dessert was a bit long. Overall, a great spot for a special dinner.\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17dd9c02-d23e-42b1-b520-ee91346bff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: LABEL_0 (Confidence: 0.99)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review = \"Great food, friendly staff, nice ambiance. A bit pricey but worth it.\"\n",
    "print(analyze_restaurant(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb8f51fa-0170-4d1c-a708-d3bfbc2c7fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 11079\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2f27ff6-fa89-4ef2-8243-e3967fc4e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'w1rA19kVKKsWz8gTZB1F8A',\n",
       " 'user_id': 'WCHkk639H3ygjRSliIeWqQ',\n",
       " 'business_id': 'PBtZNTQl5tRReeC8It1G7g',\n",
       " 'stars': 5.0,\n",
       " 'useful': 0,\n",
       " 'funny': 0,\n",
       " 'cool': 0,\n",
       " 'text': \"Love this place! My first visit was for a work conference more than 2 years ago, and now its my favorite vacation spot. I've stayed in every type of room and my favorite is the junior suite. It's large enough to bring your friends and share the room for a long weekend, and the balcony view of the bay plus the quiet and beautiful setting farther down from the pool make it worth the extra few dollars.\\n\\nEvery time we visit we note how pleasant and helpful the staff are to us. Violet in the women's lounge made our current visit absolutely amazing! Our room service staff have been top notch, providing extras of our favorites when asked. \\n\\nThe spa amenities are lovely and relaxing. Multiple pools are available inside and out, sauna and steam rooms, amazing shower products are complimentary in the showers. In the spa lounges you'll find complimentary coffee - and the coffee is glorious!\\n\\nThere are excellent restaurants up and down Main Street, an easy walk from the resort, and we've tried nearly all of them. We also frequent the Fountain Grille on site and have never been disappointed. Prices are very reasonable for the quality of the food, and the limoncello cake - wow. \\n\\nI'm writing this review while sitting on the balcony watching the car lights on the causeway and lights of Tampa across the bay. We've checked our calendars and are planning our next long weekend. Can't wait to get back.\",\n",
       " 'date': '2018-04-15 00:56:26',\n",
       " 'sentiment': 'positive'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[347]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ffa6e-d11d-489b-ab48-8116ab547d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
