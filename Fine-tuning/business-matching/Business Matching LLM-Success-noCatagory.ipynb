{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a3c573-5a45-436d-acc1-ec8d2c4f8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf results/ wandb/ fine_tuned_model_10k/ fine_tuned_model_improved/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b189e-9510-47f8-92d8-95d9b7945d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î: 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800000/800000 [03:36<00:00, 3693.46 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200000/200000 [00:51<00:00, 3897.65 examples/s]\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/ntadmin/miniconda3/lib/python3.12/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maekanun2020\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/admin/Business-Matching-Success/wandb/run-20240817_003552-c996tjxm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aekanun2020/huggingface/runs/c996tjxm' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/aekanun2020/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aekanun2020/huggingface' target=\"_blank\">https://wandb.ai/aekanun2020/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aekanun2020/huggingface/runs/c996tjxm' target=\"_blank\">https://wandb.ai/aekanun2020/huggingface/runs/c996tjxm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type dict that is 1310800 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type dict that is 961280 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70412' max='250000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 70412/250000 2:02:49 < 5:13:15, 9.55 it/s, Epoch 1.41/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.609200</td>\n",
       "      <td>3.684651</td>\n",
       "      <td>0.392415</td>\n",
       "      <td>0.313430</td>\n",
       "      <td>0.314384</td>\n",
       "      <td>0.392415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ GPU 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "def load_data(business_file, review_file, sample_size=1000000):\n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• business\n",
    "    businesses = {}\n",
    "    with open(business_file, 'r') as f:\n",
    "        for line in f:\n",
    "            business = json.loads(line)\n",
    "            businesses[business['business_id']] = business\n",
    "\n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• review\n",
    "    reviews = []\n",
    "    with open(review_file, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= sample_size:\n",
    "                break\n",
    "            review = json.loads(line)\n",
    "            if review['business_id'] in businesses:\n",
    "                reviews.append(review)\n",
    "\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame\n",
    "    df = pd.DataFrame(reviews)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• business ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô DataFrame (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô business_name)\n",
    "    df['categories'] = df['business_id'].map(lambda x: businesses[x].get('categories', ''))\n",
    "    df['city'] = df['business_id'].map(lambda x: businesses[x]['city'])\n",
    "\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á full_text ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ business_name\n",
    "    ### df['full_text'] = df.apply(lambda row: f\"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {row['categories']}\\n‡πÄ‡∏°‡∏∑‡∏≠‡∏á: {row['city']}\\n‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {row['stars']}/5\\n‡∏£‡∏µ‡∏ß‡∏¥‡∏ß: {row['text']}\\n\\n\", axis=1)\n",
    "    ### ‡∏ï‡∏±‡∏î catagory ‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á model\n",
    "    df['full_text'] = df.apply(lambda row: f\"‡πÄ‡∏°‡∏∑‡∏≠‡∏á: {row['city']}\\n‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {row['stars']}/5\\n‡∏£‡∏µ‡∏ß‡∏¥‡∏ß: {row['text']}\\n\\n\", axis=1)\n",
    "    \n",
    "    return df, businesses\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "df, businesses = load_data('../yelp_academic_dataset_business.json', '../yelp_academic_dataset_review.json', sample_size=1000000)\n",
    "print(f\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î: {len(df)}\")\n",
    "\n",
    "# 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö fine-tuning\n",
    "df['label'] = df['business_id']\n",
    "label_to_id = {label: id for id, label in enumerate(df['label'].unique())}\n",
    "id_to_label = {id: label for label, id in label_to_id.items()}\n",
    "df['label_id'] = df['label'].map(label_to_id)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df[['full_text', 'label_id']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['full_text', 'label_id']])\n",
    "\n",
    "# 4. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_and_prepare(examples):\n",
    "    tokenized = tokenizer(examples['full_text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    tokenized['labels'] = examples['label_id']\n",
    "    return tokenized\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_and_prepare, batched=True, remove_columns=train_dataset.column_names)\n",
    "tokenized_val = val_dataset.map(tokenize_and_prepare, batched=True, remove_columns=val_dataset.column_names)\n",
    "\n",
    "# 5. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_to_id))\n",
    "model.to('cuda:0')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    remove_unused_columns=False,\n",
    "    no_cuda=False,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 6. Fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "print(\"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•...\")\n",
    "trainer.train()\n",
    "print(\"Fine-tune ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô\")\n",
    "\n",
    "# 7. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "trainer.save_model(\"./fine_tuned_model_improved\")\n",
    "print(\"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea811d0f-865c-48b0-bbb6-8581038c9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ matching\n",
    "def match_business_to_text(user_text, top_n=5):\n",
    "    inputs = tokenizer(user_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to('cuda:0')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    top_n_probs, top_n_indices = torch.topk(probabilities, top_n)\n",
    "    \n",
    "    results = []\n",
    "    for prob, idx in zip(top_n_probs[0], top_n_indices[0]):\n",
    "        business_id = id_to_label[idx.item()]\n",
    "        print (\"MODEL's ANSWER ============> \", business_id)\n",
    "        business_info = businesses[business_id]\n",
    "        results.append({\n",
    "            'business_id': business_id,\n",
    "            'name': business_info['name'],\n",
    "            'categories': business_info.get('categories', ''),\n",
    "            'city': business_info['city'],\n",
    "            'probability': prob.item()\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 9. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "def display_results(results):\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. {result['name']}\")\n",
    "        print(f\"   Business ID: {result['business_id']}\")\n",
    "        print(f\"   Categories: {result['categories']}\")\n",
    "        print(f\"   City: {result['city']}\")\n",
    "        print(f\"   Probability: {result['probability']:.4f}\")\n",
    "        print(f\"   Match level: {get_match_level(result['probability'])}\")\n",
    "        \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ô‡∏µ‡πâ\n",
    "        print(\"\\n   Reviews:\")\n",
    "        business_reviews = df[df['business_id'] == result['business_id']]['text'].tolist()\n",
    "        for j, review in enumerate(business_reviews[:3], 1):  # ‡πÅ‡∏™‡∏î‡∏á 3 ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÅ‡∏£‡∏Å\n",
    "            print(f\"   Review {j}: {review[:200]}...\")  # ‡πÅ‡∏™‡∏î‡∏á 200 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏µ‡∏ß‡∏¥‡∏ß\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "def get_match_level(probability):\n",
    "    if probability > 0.8:\n",
    "        return \"Very High\"\n",
    "    elif probability > 0.6:\n",
    "        return \"High\"\n",
    "    elif probability > 0.4:\n",
    "        return \"Moderate\"\n",
    "    elif probability > 0.2:\n",
    "        return \"Low\"\n",
    "    else:\n",
    "        return \"Very Low\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81af92d-b599-41f9-becb-6c1e8fbaf58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "user_text = \"‡∏â‡∏±‡∏ô‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏°‡∏≠‡∏á‡∏´‡∏≤‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏¥‡∏ï‡∏≤‡πÄ‡∏•‡∏µ‡∏¢‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏≤‡∏™‡∏ï‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏û‡∏¥‡∏ã‡∏ã‡πà‡∏≤‡∏≠‡∏£‡πà‡∏≠‡∏¢‡πÜ\"\n",
    "results = match_business_to_text(user_text)\n",
    "\n",
    "print(f\"User Text: {user_text}\\n\")\n",
    "print(\"Top 5 Matching Businesses:\")\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eeda55-4902-4f39-acab-700ce35722f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "user_text = \"I'm looking for an Italian restaurant with delicious pasta and pizza.\"\n",
    "results = match_business_to_text(user_text)\n",
    "\n",
    "print(f\"User Text: {user_text}\\n\")\n",
    "print(\"Top 5 Matching Businesses:\")\n",
    "display_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f4a67-3f05-45a0-a885-4561372e88d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
